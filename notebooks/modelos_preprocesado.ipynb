{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 4)\n",
    "\n",
    "df = pd.read_csv('data/raw/titanic.csv')\n",
    "df.head()\n",
    "\n",
    "# Preprocesado y Modelos\n",
    "\n",
    "#En este notebook realizamos el preprocesamiento del dataset del Titanic y probamos diferentes modelos de Machine Learning para predecir la supervivencia. Este paso forma parte del pipeline del proyecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722c3d1",
   "metadata": {},
   "source": [
    "# Preprocesado y modelos – Titanic\n",
    "\n",
    "En este notebook probamos distintos **pasos de preprocesado** y **modelos de Machine Learning** \n",
    "para predecir la supervivencia de los pasajeros del Titanic.\n",
    "\n",
    "Partimos del análisis exploratorio realizado en el notebook `EDA de Isabella` y aquí \n",
    "nos centramos en:\n",
    "\n",
    "1. Seleccionar las variables más relevantes.\n",
    "2. Definir un pipeline de preprocesado (nulos, codificación, escalado).\n",
    "3. Entrenar y comparar varios modelos de clasificación.\n",
    "4. Elegir un modelo base para el servicio de predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a53eab",
   "metadata": {},
   "source": [
    "## 1. Carga de datos\n",
    "\n",
    "Cargamos el mismo dataset utilizado en el EDA, a partir de la carpeta `data/raw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/raw/titanic.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "## 2. Selección de variables\n",
    "\n",
    "#Para este experimento vamos a usar las siguientes columnas como *features*:\n",
    "\n",
    "##- `pclass` – clase del billete  \n",
    "#- `sex` – sexo  \n",
    "#- `age` – edad  \n",
    "#- `sibsp` – nº de hermanos/cónyuges a bordo  \n",
    "#- `parch` – nº de padres/hijos a bordo  \n",
    "#- `fare` – tarifa pagada  \n",
    "#- `embarked` – puerto de embarque  \n",
    "\n",
    "#La variable objetivo será `survived` (0 = no sobrevive, 1 = sobrevive).\n",
    "\n",
    "\n",
    "num_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_features = [\"Sex\", \"Embarked\"]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]\n",
    "target_col = \"survived\"\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cba876",
   "metadata": {},
   "source": [
    "## 3. Pipeline de preprocesado\n",
    "\n",
    "Definimos un pipeline que haga automáticamente:\n",
    "\n",
    "- Imputación de valores nulos en variables numéricas (con la media).\n",
    "- Imputación de nulos en categóricas (con la categoría más frecuente).\n",
    "- Escalado de variables numéricas.\n",
    "- Codificación *one-hot* de variables categóricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = [\"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "categorical_features = [\"pclass\", \"sex\", \"embarked\"]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba863c",
   "metadata": {},
   "source": [
    "## 4. Modelos a comparar\n",
    "\n",
    "Vamos a probar dos modelos sencillos:\n",
    "\n",
    "1. **Regresión logística** – modelo lineal rápido y fácil de interpretar.  \n",
    "2. **Random Forest** – conjunto de árboles de decisión, capaz de capturar relaciones no lineales.\n",
    "\n",
    "En ambos casos utilizaremos el *mismo pipeline de preprocesado* definido antes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline con Regresión Logística\n",
    "log_reg_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(max_iter=1000)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline con Random Forest\n",
    "rf_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=42\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg_clf,\n",
    "    \"Random Forest\": rf_clf,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(f\"Accuracy en test: {acc:.3f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b17e61",
   "metadata": {},
   "source": [
    "## 5. Comparación de resultados\n",
    "\n",
    "En la celda anterior hemos entrenado ambos modelos y calculado el \n",
    "**accuracy** sobre el conjunto de test. A continuación mostramos \n",
    "un pequeño resumen comparativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af57d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_lr = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])\n",
    "\n",
    "model_lr.fit(X, y)\n",
    "y_pred_lr = model_lr.predict(X)\n",
    "accuracy_lr = accuracy_score(y, y_pred_lr)\n",
    "accuracy_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "model_rf.fit(X, y)\n",
    "y_pred_rf = model_rf.predict(X)\n",
    "accuracy_rf = accuracy_score(y, y_pred_rf)\n",
    "accuracy_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443147a",
   "metadata": {},
   "source": [
    "## 6. Conclusiones\n",
    "\n",
    "- El modelo con mejor rendimiento ha sido: **(rellenar según resultados)**.\n",
    "- El pipeline de preprocesado nos permite manejar nulos y variables \n",
    "  categóricas de forma automática.\n",
    "- Este notebook sirve como base para decidir qué modelo integrar en el \n",
    "  servicio de predicción del proyecto (`src/`).\n",
    "\n",
    "> **Nota:** aquí puedes escribir 3–4 bullets con tus conclusiones personales \n",
    "> (lo que pide el profe).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07feb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844e771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3009b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
